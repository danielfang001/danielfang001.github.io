---
layout: post
title: Regression Project
---
In order to predict the prospective use of share bikes in London, I took a preprocessed dataset that reflects the count of bike shares and other variables about the weather and time at the time. To process the data properly, I didn’t have to do any cleaning, and I simply modified the data by dropping a column called timestamp which provides the least correlation with my predicting variable. When it comes to transforming numerical data into scaled polynomial features, I directly split the numerical variable columns from the categorical ones. Since the categorical ones have already contained numerical values instead of categorical values, I didn’t imply any one hot column to transfer the type of the values. After the split, I implemented pipeline, combining polynomial feature and standard scaler function from scikit learn, and combined the processed numerical values with the original categorical values. Here, the degree I want to use for the polynomial feature is uncertain, so the next step I did is to find the optimal degree that gives the least mean error for training and testing data which turns out to be degree 2. The plotted U shape graph allows me to directly envision the difference between two errors. The dataset was then ready for training a model. I ran it through ridgecv that intuitively combines cross-validation and ridge regression. This is a powerful tool to control the alpha, the level of smoothness, of the model so that it doesn’t overfit or underfit; nevertheless, the adjusted r^2 value is only around 28%, which provides a reluctant conclusion with little value. Eventually, the code is able to tell me the optimal alpha value and the information (coefficient and intercept) of the model ’s polynomial equation in association to each variable. However, the direct output from the model combines the categorical information with a stack of columns with random names. I was able to find what each column represent by comparing the original data and the data after imposing polynomial feature. Eventually, I have written out the estimated equation to predict the count of bike share in London. .
